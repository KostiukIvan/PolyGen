import torch
from torch.nn.functional import pad


class VertexTokenizer:
    def __init__(self, padding=True, max_seq_len=2400, device=None):
        # NOTE: max_seq_len % reformer__bucket_size == 0 !!!
        self.max_seq_len = max_seq_len
        self.tokens = {
            'bos': torch.tensor([0]).to(device),
            'eos': torch.tensor([1]).to(device),
            'pad': torch.tensor([2]).to(device),
            'ept': torch.tensor([2]).to(device),
        }
        self.padd = padding
        self.device = device

    def __call__(self, vertices):
        return self.tokenize(vertices)

    def tokenize(self, vertices):
        """
        Input:
        vertices : torch.tensor of shape [:, 3]
        """
        # assert vertices.size(1) == 3 and len(vertices.shape) == 2

        vertices = torch.flatten(vertices).to(self.device)
        vertices = torch.cat([self.tokens['bos'],
                              vertices,
                              self.tokens['eos']])
        axises_tokens = torch.cat([self.tokens['ept'],
                                   torch.arange(len(vertices) - 2).to(self.device) % 3 + 1,
                                   self.tokens['ept']])
        position_tokens = torch.cat([self.tokens['ept'],
                                     torch.arange(len(vertices) - 2).to(self.device) // 3 + 1,
                                     self.tokens['ept']])
        target_vertices = torch.cat([vertices[1:], self.tokens['pad']])
        assert vertices.shape == axises_tokens.shape == position_tokens.shape == target_vertices.shape

        if self.padd:
            padding_len = self.max_seq_len - len(vertices) if self.max_seq_len > len(vertices) else 0
            vertices = pad(vertices, (0, padding_len), value=self.tokens['pad'][0])
            axises_tokens = pad(axises_tokens, (0, padding_len), value=self.tokens['pad'][0])
            position_tokens = pad(position_tokens, (0, padding_len), value=self.tokens['pad'][0])
            target_vertices = pad(target_vertices, (0, padding_len), value=self.tokens['pad'][0])
            # TODO: Add padding mask
            padding_mask = torch.where(vertices == self.tokens['pad'],
                                        torch.ones_like(vertices),
                                        torch.zeros_like(vertices) ).type(torch.bool)
        return {"vertices_tokens": vertices,
                "axises_tokens": axises_tokens,
                "position_tokens": position_tokens,
                "target_vertices": target_vertices,
                "padding_mask": padding_mask}

    def detokenize(self, vertices_reconstruction, seq_len=2400, is_target=False):
        #assert len(vertices_reconstruction.shape) == 2 # only one element could be processed
        # note: Targets needs to be extracted in order to calculate chamfer dist.
        if not is_target:
            vertices_reconstruction = torch.max(vertices_reconstruction, dim=0)[1]

        vertices = torch.reshape(vertices_reconstruction, shape=(-1, 3))
        vertices = vertices.float()
        vertices /= 256
        return vertices

    def get_initial_sampling_tokens(self, num_samples=1, init_len=0):
        """
        Get initial tokens required for generation.
        (Vertices are generated by an autoregressive transformer that's why we need those initial sequences.)
        """
        vertices_tokens = torch.tensor([self.tokens["bos"][0]] * num_samples).unsqueeze(0).reshape(num_samples, 1).to(self.device)
        vertices_tokens = pad(vertices_tokens, (0, self.max_seq_len - 1), value=self.tokens['pad'][0]).to(self.device)

        axises_tokens = torch.tensor([self.tokens["ept"][0]] * num_samples).unsqueeze(0).reshape(num_samples, 1).to(self.device)
        axises_tokens = pad(axises_tokens, (0, self.max_seq_len - 1), value=self.tokens['pad'][0]).to(self.device)

        position_tokens = torch.tensor([self.tokens["ept"][0]] * num_samples).unsqueeze(0).reshape(num_samples, 1).to(self.device)
        position_tokens = pad(position_tokens, (0, self.max_seq_len - 1), value=self.tokens['pad'][0]).to(self.device)

        if init_len > 0:
            vertices_tokens[:,1:init_len + 1] = torch.randint(0, 255, (vertices_tokens.shape[0], init_len))
            axises_tokens[:,1:init_len + 1] = torch.tensor([torch.arange(init_len).to(self.device) % 3 + 1])
            position_tokens[:,1:init_len + 1] = torch.tensor([torch.arange(init_len).to(self.device) // 3 + 1])
           

        padding_mask = torch.where(vertices_tokens == self.tokens['pad'],
                            torch.ones_like(vertices_tokens),
                            torch.zeros_like(vertices_tokens)).type(torch.bool)
    
        return {"vertices_tokens": vertices_tokens,
                "axises_tokens": axises_tokens,
                "position_tokens": position_tokens,
                "padding_mask": padding_mask
                }, init_len


    def tokenize_without_end(self, vertices):
        """
        Get initial tokens required for generation.
        (Vertices are generated by an autoregressive transformer that's why we need those initial sequences.)
        """
        num_samples = vertices.shape[0]
        len_samples = vertices.shape[1]
        vertices = torch.flatten(vertices).to(self.device)

        vertices_tokens = torch.cat([self.tokens["bos"], vertices])
        vertices_tokens = pad(vertices_tokens, (0, self.max_seq_len - 1 - len_samples), value=self.tokens['pad'][0]).to(self.device)

        axises_tokens = torch.arange(len(vertices)).to(self.device) % 3 + 1
        axises_tokens = torch.cat([self.tokens["ept"], axises_tokens])
        axises_tokens = pad(axises_tokens, (0, self.max_seq_len - 1 - len_samples), value=self.tokens['pad'][0]).to(self.device)

        position_tokens = torch.arange(len(vertices)).to(self.device) // 3 + 1
        position_tokens = torch.cat([self.tokens["ept"], position_tokens])
        position_tokens = pad(position_tokens, (0, self.max_seq_len - 1 - len_samples), value=self.tokens['pad'][0]).to(self.device)
        
        padding_mask = torch.where(vertices_tokens == self.tokens['pad'],
                            torch.ones_like(vertices_tokens),
                            torch.zeros_like(vertices_tokens)).type(torch.bool)
    
        return {"vertices_tokens": vertices_tokens,
                "axises_tokens": axises_tokens,
                "position_tokens": position_tokens,
                "padding_mask": padding_mask
                }
